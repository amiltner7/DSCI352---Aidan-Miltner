{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 2: classification methods\n",
    "\n",
    "This lab is due by midnight Saturday Feb 19th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.9/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You will need to change this for your environment\n",
    "DATA_ROOT = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the 'index_col' argument here, which makes slicing easier below.\n",
    "market = pd.read_csv(DATA_ROOT + 'Smarket.csv', index_col=0, parse_dates=True)\n",
    "market.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    Logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Fri, 18 Feb 2022   Deviance:                       1727.6\n",
      "Time:                                          21:46:00   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4   Pseudo R-squ. (CS):           0.002868\n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n",
      "predicted probabilities: [0.49291587 0.51853212 0.51886117 0.48477764 0.48921884 0.49304354\n",
      " 0.50734913 0.49077084 0.48238647 0.51116222]\n",
      "qualitative predictions: ['Up', 'Down', 'Down', 'Up', 'Up', 'Up', 'Down', 'Up', 'Up', 'Down']\n",
      "confusion matrix:\n",
      " [[145 141]\n",
      " [457 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.507     0.241     0.327       602\n",
      "          Up      0.526     0.782     0.629       648\n",
      "\n",
      "    accuracy                          0.522      1250\n",
      "   macro avg      0.516     0.512     0.478      1250\n",
      "weighted avg      0.517     0.522     0.483      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will re-use this formula with other learning methods below\n",
    "all_lags = 'Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume'\n",
    "\n",
    "marklr = smf.glm(formula=all_lags, data=market, family=sm.families.Binomial())\n",
    "mlr_res = marklr.fit()\n",
    "print(mlr_res.summary())\n",
    "\n",
    "# The predicted values are probabilities\n",
    "mlr_prob = mlr_res.predict()\n",
    "print('predicted probabilities:', mlr_prob[0:10])\n",
    "\n",
    "# Here we create a set of qualitative predictions by thresholding on the probabilities\n",
    "predictions_nominal = [\"Up\" if x < 0.5 else \"Down\" for x in mlr_prob]\n",
    "print('qualitative predictions:', predictions_nominal[0:10])\n",
    "\n",
    "# Note: the '.T' here to take the transpose so that the true classes are columns and the predicted classes are rows,\n",
    "# matching the class slides\n",
    "print('confusion matrix:\\n', confusion_matrix(market[\"Direction\"], predictions_nominal).T)\n",
    "\n",
    "print(classification_report(market[\"Direction\"], predictions_nominal, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets, training on everything up to and including 2004 data\n",
    "# and testing on 2005 and later data:\n",
    "x_train = market[:'2004'][:]\n",
    "y_train = market[:'2004']['Direction']\n",
    "\n",
    "x_test = market['2005':][:]\n",
    "y_test = market['2005':]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                  998\n",
      "Model:                                              GLM   Df Residuals:                      991\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    Logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -690.55\n",
      "Date:                                  Fri, 18 Feb 2022   Deviance:                       1381.1\n",
      "Time:                                          21:46:00   Pearson chi2:                     998.\n",
      "No. Iterations:                                       4   Pseudo R-squ. (CS):           0.002162\n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1912      0.334     -0.573      0.567      -0.845       0.463\n",
      "Lag1           0.0542      0.052      1.046      0.295      -0.047       0.156\n",
      "Lag2           0.0458      0.052      0.884      0.377      -0.056       0.147\n",
      "Lag3          -0.0072      0.052     -0.139      0.889      -0.108       0.094\n",
      "Lag4          -0.0064      0.052     -0.125      0.901      -0.108       0.095\n",
      "Lag5           0.0042      0.051      0.083      0.934      -0.096       0.104\n",
      "Volume         0.1163      0.240      0.485      0.628      -0.353       0.586\n",
      "==============================================================================\n",
      "confusion matrix:\n",
      " [[77 97]\n",
      " [34 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.69      0.54       111\n",
      "          Up       0.56      0.31      0.40       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.50      0.50      0.47       252\n",
      "weighted avg       0.51      0.48      0.46       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression to the training data and (below) evaluate it using the test data\n",
    "mlr_04 = smf.glm(formula=all_lags, data=x_train, family=sm.families.Binomial())\n",
    "res_04 = mlr_04.fit()\n",
    "print(res_04.summary())\n",
    "\n",
    "# Build predictions of the test data using a 0.5 threshold\n",
    "prob_04 = res_04.predict(x_test)\n",
    "pred_04 = ['Up' if x < 0.5 else 'Down' for x in prob_04]\n",
    "\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_04).T)\n",
    "print(classification_report(y_test, pred_04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Your job: build and test a LR model with only the two predictors with the best p-values above\n",
    "\n",
    "Looking at the model summary above, that will be Lag1 and Lag2.\n",
    "\n",
    "Build the new model below, and generate a new confusion matrix and classification report as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                  998\n",
      "Model:                                              GLM   Df Residuals:                      995\n",
      "Model Family:                                  Binomial   Df Model:                            2\n",
      "Link Function:                                    Logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -690.70\n",
      "Date:                                  Fri, 18 Feb 2022   Deviance:                       1381.4\n",
      "Time:                                          21:46:00   Pearson chi2:                     998.\n",
      "No. Iterations:                                       4   Pseudo R-squ. (CS):           0.001865\n",
      "Covariance Type:                              nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0322      0.063     -0.508      0.611      -0.156       0.092\n",
      "Lag1           0.0556      0.052      1.076      0.282      -0.046       0.157\n",
      "Lag2           0.0445      0.052      0.861      0.389      -0.057       0.146\n",
      "==============================================================================\n",
      "confusion matrix:\n",
      " [[ 35  35]\n",
      " [ 76 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.32      0.39       111\n",
      "          Up       0.58      0.75      0.66       141\n",
      "\n",
      "    accuracy                           0.56       252\n",
      "   macro avg       0.54      0.53      0.52       252\n",
      "weighted avg       0.55      0.56      0.54       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a model using just lag1 and lag2 and test it (skip the code for the lab)\n",
    "\n",
    "slr = smf.glm(formula='Direction ~ Lag1 + Lag2', data=x_train, family=sm.families.Binomial())\n",
    "slr_fit = slr.fit()\n",
    "print(slr_fit.summary())\n",
    "prob_slr = slr_fit.predict(x_test)\n",
    "pred_slr = ['Up' if x < 0.5 else 'Down' for x in prob_slr]\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_slr).T)\n",
    "print(classification_report(y_test, pred_slr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions 1 - 3\n",
    "\n",
    "Question 1: How does the overall accuracy of this smaller model compare\n",
    "\n",
    "Question 2: Show how to use the confusion matrix to derive the overall accuracy as shown in the classification report.\n",
    "(The calculations can be typed here and do not have to be shown with code.)\n",
    "\n",
    "Question 3: How does the interpretability of the second model compare with the first in your opinion? Justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The overall accuracy of the model with just Lag1 and Lag2 is better than the model with all of the variables. Once we split the data into training and testing sets, the accuracy of the first model with all of the lags and Volume is 0.48 while the model with only lag 1 and lag 2 has an accuracy of 0.56. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) To get overall accuracy, you divide the total number of correct classifications (35+106=141) by the total number of observations (35+35+76+106=252). So, you get 141/252 which is 0.56. We can test this formula on the first regression with all of the lags and Volume as well: (77+44)/(77+44+97+34) = 0.48."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The interpretability does not change much between the two models because they are both logistic regression models. However, you could say the second model is easier to interpret because there are less variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "We now build a model for the same data with K-Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Restrict the training and test data to only have the 'Lag1' and 'Lag2' predictor variables.\n",
    "# (This code fits the model and makes predictions in one line.)\n",
    "pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "\n",
    "print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix:\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.43      0.45       111\n",
      "          Up       0.58      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN with K of 1 performed poorly, let's try K of 3\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "\n",
    "print('KNN confusion matrix:\\n', confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Your task: try some more values for K (number of neighbors) and report on which has best overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix with k= 1 :\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.39      0.41       111\n",
      "          Up       0.55      0.59      0.57       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.50      0.50      0.50       252\n",
      "\n",
      "KNN confusion matrix with k= 2 :\n",
      " [[74 93]\n",
      " [37 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.67      0.53       111\n",
      "          Up       0.56      0.34      0.42       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.50      0.50      0.48       252\n",
      "weighted avg       0.51      0.48      0.47       252\n",
      "\n",
      "KNN confusion matrix with k= 3 :\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.43      0.45       111\n",
      "          Up       0.58      0.61      0.59       141\n",
      "\n",
      "    accuracy                           0.53       252\n",
      "   macro avg       0.52      0.52      0.52       252\n",
      "weighted avg       0.53      0.53      0.53       252\n",
      "\n",
      "KNN confusion matrix with k= 4 :\n",
      " [[71 82]\n",
      " [40 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.46      0.64      0.54       111\n",
      "          Up       0.60      0.42      0.49       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.53      0.53      0.51       252\n",
      "weighted avg       0.54      0.52      0.51       252\n",
      "\n",
      "KNN confusion matrix with k= 5 :\n",
      " [[40 59]\n",
      " [71 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.40      0.36      0.38       111\n",
      "          Up       0.54      0.58      0.56       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.47      0.47      0.47       252\n",
      "weighted avg       0.48      0.48      0.48       252\n",
      "\n",
      "KNN confusion matrix with k= 6 :\n",
      " [[63 79]\n",
      " [48 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.44      0.57      0.50       111\n",
      "          Up       0.56      0.44      0.49       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.50      0.50      0.50       252\n",
      "weighted avg       0.51      0.50      0.50       252\n",
      "\n",
      "KNN confusion matrix with k= 7 :\n",
      " [[41 65]\n",
      " [70 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.39      0.37      0.38       111\n",
      "          Up       0.52      0.54      0.53       141\n",
      "\n",
      "    accuracy                           0.46       252\n",
      "   macro avg       0.45      0.45      0.45       252\n",
      "weighted avg       0.46      0.46      0.46       252\n",
      "\n",
      "KNN confusion matrix with k= 8 :\n",
      " [[63 82]\n",
      " [48 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.43      0.57      0.49       111\n",
      "          Up       0.55      0.42      0.48       141\n",
      "\n",
      "    accuracy                           0.48       252\n",
      "   macro avg       0.49      0.49      0.48       252\n",
      "weighted avg       0.50      0.48      0.48       252\n",
      "\n",
      "KNN confusion matrix with k= 9 :\n",
      " [[45 61]\n",
      " [66 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.42      0.41      0.41       111\n",
      "          Up       0.55      0.57      0.56       141\n",
      "\n",
      "    accuracy                           0.50       252\n",
      "   macro avg       0.49      0.49      0.49       252\n",
      "weighted avg       0.49      0.50      0.49       252\n",
      "\n",
      "KNN confusion matrix with k= 10 :\n",
      " [[67 77]\n",
      " [44 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.47      0.60      0.53       111\n",
      "          Up       0.59      0.45      0.51       141\n",
      "\n",
      "    accuracy                           0.52       252\n",
      "   macro avg       0.53      0.53      0.52       252\n",
      "weighted avg       0.54      0.52      0.52       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# That was an improvement, try some other values to compare\n",
    "\n",
    "for k in range(10):\n",
    "    # Your code here (and delete the 'pass' line)\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k+1)\n",
    "    pred = knn.fit(x_train[['Lag1', 'Lag2']], y_train).predict(x_test[['Lag1', 'Lag2']])\n",
    "    print('KNN confusion matrix with k=', (k+1), ':\\n', confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred))\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 4:\n",
    "\n",
    "Question 4: Which of the other K values that you tried for K-Nearest neighbors worked the best, based on overall accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Based on the K vaues I tried (1-10), K=3 had the best overall accuracy with 0.53 (53% accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.49198397 0.50801603]\n",
      "Means: [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n",
      "Coefficients: [[-0.05544078 -0.0443452 ]]\n",
      "[[ 35  76]\n",
      " [ 35 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.50      0.32      0.39       111\n",
      "          Up       0.58      0.75      0.66       141\n",
      "\n",
      "    accuracy                           0.56       252\n",
      "   macro avg       0.54      0.53      0.52       252\n",
      "weighted avg       0.55      0.56      0.54       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "ldm = lda.fit(x_train[['Lag1', 'Lag2']], y_train)\n",
    "\n",
    "print('Priors:', ldm.priors_)\n",
    "print('Means:', ldm.means_)\n",
    "print('Coefficients:', ldm.coef_)\n",
    "\n",
    "pred = ldm.predict(x_test[['Lag1', 'Lag2']])\n",
    "print(confusion_matrix(pred, y_test).T)\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.49198397 0.50801603]\n",
      "Means: [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n",
      "[[ 30  81]\n",
      " [ 20 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down       0.60      0.27      0.37       111\n",
      "          Up       0.60      0.86      0.71       141\n",
      "\n",
      "    accuracy                           0.60       252\n",
      "   macro avg       0.60      0.56      0.54       252\n",
      "weighted avg       0.60      0.60      0.56       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdm = qda.fit(x_train[['Lag1', 'Lag2']], y_train)\n",
    "\n",
    "print('Priors:', qdm.priors_)\n",
    "print('Means:', qdm.means_)\n",
    "\n",
    "q_pred = qdm.predict(x_test[['Lag1', 'Lag2']])\n",
    "print(confusion_matrix(q_pred, y_test).T)\n",
    "print(classification_report(y_test, q_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Question 5: which of the methods that you tried produced the best results for predicting Direction from Lag1 and Lag2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Quadratic discriminant analysis produced the best results for predicting Direction from Lag1 and Lag2. LDA did better than k-nearest neighbors because the overall accuracy was 0.56, higher than any of the KNN models we tried. LDA had the same accuracy as the logistic regression with 0.56. But, QDA beat them all with an overall accuracy of 0.60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carseats data\n",
    "\n",
    "Now load the carseats data and try to predict whether the store is located in the US from the other predictor variables.\n",
    "\n",
    "Report below on your findings about (at least) three different learning approaches, comparing their overall accuracy.\n",
    "\n",
    "If you use K-nearest neighbors, be sure to try a few different values for K and report on the best one, showing your work.\n",
    "\n",
    "If you use logistic regression, try to find a simple model with good accuracy by dropping predictors with high p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seats = pd.read_csv(DATA_ROOT + 'Carseats.csv')\n",
    "seats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>9.24</td>\n",
       "      <td>126</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>436</td>\n",
       "      <td>126</td>\n",
       "      <td>Medium</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>5.98</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>447</td>\n",
       "      <td>134</td>\n",
       "      <td>Medium</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>6.97</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>414</td>\n",
       "      <td>96</td>\n",
       "      <td>Bad</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.13</td>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>239</td>\n",
       "      <td>109</td>\n",
       "      <td>Good</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8.25</td>\n",
       "      <td>136</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>241</td>\n",
       "      <td>131</td>\n",
       "      <td>Medium</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "308   9.24        126      80           19         436    126    Medium   52   \n",
       "366   5.98        124      56           11         447    134    Medium   53   \n",
       "284   6.97        106      46           11         414     96       Bad   79   \n",
       "21   12.13        134      29           12         239    109      Good   62   \n",
       "31    8.25        136      58           16         241    131    Medium   44   \n",
       "\n",
       "     Education Urban  \n",
       "308         10   Yes  \n",
       "366         12    No  \n",
       "284         17    No  \n",
       "21          18    No  \n",
       "31          18   Yes  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick random training and test sets for your analysis:\n",
    "x_train, x_test, y_train, y_test = train_test_split(seats, seats['US'],\n",
    "                                                    train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Hint: if you need to remove some predictors for training or testing in any of the learning methods,\n",
    "# you can use the pandas 'drop' function to drop the corresponding columns, e.g.\n",
    "x_train.drop(columns=['US']).head()\n",
    "\n",
    "# Hint 2: if you want to write a formula and include a lot of columns, you could use the method\n",
    "# that was shown in lab 1, e.g.:\n",
    "#sm.OLS.from_formula('medv ~ ' + '+'.join(df.columns.difference(['medv', 'age', 'indus'])), df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     ['US[No]', 'US[Yes]']   No. Observations:                  320\n",
      "Model:                               GLM   Df Residuals:                      308\n",
      "Model Family:                   Binomial   Df Model:                           11\n",
      "Link Function:                     Logit   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -83.021\n",
      "Date:                   Fri, 18 Feb 2022   Deviance:                       166.04\n",
      "Time:                           21:46:01   Pearson chi2:                     236.\n",
      "No. Iterations:                        8   Pseudo R-squ. (CS):             0.5449\n",
      "Covariance Type:               nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               0.7558      2.393      0.316      0.752      -3.935       5.447\n",
      "ShelveLoc[T.Good]      -1.7991      1.174     -1.533      0.125      -4.099       0.501\n",
      "ShelveLoc[T.Medium]    -0.2914      0.635     -0.459      0.647      -1.537       0.954\n",
      "Urban[T.Yes]           -0.0144      0.451     -0.032      0.975      -0.898       0.869\n",
      "Sales                   0.2446      0.200      1.224      0.221      -0.147       0.636\n",
      "CompPrice              -0.0332      0.026     -1.275      0.202      -0.084       0.018\n",
      "Income                 -0.0191      0.008     -2.460      0.014      -0.034      -0.004\n",
      "Advertising            -0.7583      0.106     -7.160      0.000      -0.966      -0.551\n",
      "Population              0.0039      0.002      2.532      0.011       0.001       0.007\n",
      "Price                   0.0250      0.022      1.110      0.267      -0.019       0.069\n",
      "Age                     0.0077      0.015      0.496      0.620      -0.023       0.038\n",
      "Education               0.0784      0.079      0.997      0.319      -0.076       0.233\n",
      "=======================================================================================\n",
      "confusion matrix:\n",
      " [[25  5]\n",
      " [ 2 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.93      0.88        27\n",
      "         Yes       0.96      0.91      0.93        53\n",
      "\n",
      "    accuracy                           0.91        80\n",
      "   macro avg       0.90      0.92      0.90        80\n",
      "weighted avg       0.92      0.91      0.91        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here. I would recommend using a different cell for each learning method:\n",
    "\n",
    "# learning method 1: Logistic Regression (LR)\n",
    "all_vars = 'US ~ Sales+CompPrice+Income+Advertising+Population+Price+ShelveLoc+Age+Education+Urban'\n",
    "\n",
    "slr = smf.glm(formula=all_vars, data=x_train, family=sm.families.Binomial())\n",
    "slr_fit = slr.fit()\n",
    "print(slr_fit.summary())\n",
    "prob_slr = slr_fit.predict(x_test)\n",
    "pred_slr = ['Yes' if x < 0.5 else 'No' for x in prob_slr]\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_slr).T)\n",
    "print(classification_report(y_test, pred_slr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     ['US[No]', 'US[Yes]']   No. Observations:                  320\n",
      "Model:                               GLM   Df Residuals:                      315\n",
      "Model Family:                   Binomial   Df Model:                            4\n",
      "Link Function:                     Logit   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -85.633\n",
      "Date:                   Fri, 18 Feb 2022   Deviance:                       171.27\n",
      "Time:                           21:46:01   Pearson chi2:                     341.\n",
      "No. Iterations:                        8   Pseudo R-squ. (CS):             0.5374\n",
      "Covariance Type:               nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       2.4419      1.133      2.155      0.031       0.221       4.663\n",
      "Income         -0.0174      0.007     -2.404      0.016      -0.032      -0.003\n",
      "Advertising    -0.7273      0.098     -7.435      0.000      -0.919      -0.536\n",
      "Population      0.0039      0.001      2.654      0.008       0.001       0.007\n",
      "Price          -0.0042      0.008     -0.539      0.590      -0.019       0.011\n",
      "===============================================================================\n",
      "confusion matrix:\n",
      " [[26  5]\n",
      " [ 1 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.96      0.90        27\n",
      "         Yes       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.91      0.93      0.92        80\n",
      "weighted avg       0.93      0.93      0.93        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now take only the 4 variables with the lowest p-values\n",
    "better_vars = 'US ~ Income+Advertising+Population+Price'\n",
    "\n",
    "slr = smf.glm(formula=better_vars, data=x_train, family=sm.families.Binomial())\n",
    "slr_fit = slr.fit()\n",
    "print(slr_fit.summary())\n",
    "prob_slr = slr_fit.predict(x_test)\n",
    "pred_slr = ['Yes' if x < 0.5 else 'No' for x in prob_slr]\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_slr).T)\n",
    "print(classification_report(y_test, pred_slr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Generalized Linear Model Regression Results                   \n",
      "=================================================================================\n",
      "Dep. Variable:     ['US[No]', 'US[Yes]']   No. Observations:                  320\n",
      "Model:                               GLM   Df Residuals:                      317\n",
      "Model Family:                   Binomial   Df Model:                            2\n",
      "Link Function:                     Logit   Scale:                          1.0000\n",
      "Method:                             IRLS   Log-Likelihood:                -88.776\n",
      "Date:                   Fri, 18 Feb 2022   Deviance:                       177.55\n",
      "Time:                           21:46:01   Pearson chi2:                     438.\n",
      "No. Iterations:                        8   Pseudo R-squ. (CS):             0.5282\n",
      "Covariance Type:               nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.6832      0.334      2.047      0.041       0.029       1.338\n",
      "Advertising    -0.7142      0.094     -7.580      0.000      -0.899      -0.530\n",
      "Population      0.0040      0.001      2.803      0.005       0.001       0.007\n",
      "===============================================================================\n",
      "confusion matrix:\n",
      " [[26  5]\n",
      " [ 1 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.96      0.90        27\n",
      "         Yes       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.91      0.93      0.92        80\n",
      "weighted avg       0.93      0.93      0.93        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We still get an accuracy of 0.86. Try only the lowest 2.\n",
    "best_vars = 'US ~ Advertising+Population'\n",
    "\n",
    "slr = smf.glm(formula=best_vars, data=x_train, family=sm.families.Binomial())\n",
    "slr_fit = slr.fit()\n",
    "print(slr_fit.summary())\n",
    "prob_slr = slr_fit.predict(x_test)\n",
    "pred_slr = ['Yes' if x < 0.5 else 'No' for x in prob_slr]\n",
    "print('confusion matrix:\\n', confusion_matrix(y_test, pred_slr).T)\n",
    "print(classification_report(y_test, pred_slr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.359375 0.640625]\n",
      "Means: [[  0.51304348 245.37391304]\n",
      " [  9.84878049 267.91707317]]\n",
      "Coefficients: [[ 0.42006905 -0.00359525]]\n",
      "[[26  1]\n",
      " [ 6 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.96      0.88        27\n",
      "         Yes       0.98      0.89      0.93        53\n",
      "\n",
      "    accuracy                           0.91        80\n",
      "   macro avg       0.90      0.92      0.91        80\n",
      "weighted avg       0.92      0.91      0.91        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning method 2: LDA (use only the best 2 predictors: Advertising and Population)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ldm = lda.fit(x_train[['Advertising', 'Population']], y_train)\n",
    "\n",
    "print('Priors:', ldm.priors_)\n",
    "print('Means:', ldm.means_)\n",
    "print('Coefficients:', ldm.coef_)\n",
    "\n",
    "pred = ldm.predict(x_test[['Advertising', 'Population']])\n",
    "print(confusion_matrix(pred, y_test).T)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: [0.359375 0.640625]\n",
      "Means: [[  0.51304348 245.37391304]\n",
      " [  9.84878049 267.91707317]]\n",
      "[[26  1]\n",
      " [ 5 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.96      0.90        27\n",
      "         Yes       0.98      0.91      0.94        53\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.91      0.93      0.92        80\n",
      "weighted avg       0.93      0.93      0.93        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learning method 3: QDA (also use Advertising and Population as predictors)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdm = qda.fit(x_train[['Advertising', 'Population']], y_train)\n",
    "\n",
    "print('Priors:', qdm.priors_)\n",
    "print('Means:', qdm.means_)\n",
    "\n",
    "q_pred = qdm.predict(x_test[['Advertising', 'Population']])\n",
    "print(confusion_matrix(q_pred, y_test).T)\n",
    "print(classification_report(y_test, q_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix with k= 1 :\n",
      " [[24  9]\n",
      " [ 3 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.89      0.80        27\n",
      "         Yes       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.85        80\n",
      "   macro avg       0.83      0.86      0.84        80\n",
      "weighted avg       0.87      0.85      0.85        80\n",
      "\n",
      "KNN confusion matrix with k= 2 :\n",
      " [[26 12]\n",
      " [ 1 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.96      0.80        27\n",
      "         Yes       0.98      0.77      0.86        53\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.83      0.87      0.83        80\n",
      "weighted avg       0.88      0.84      0.84        80\n",
      "\n",
      "KNN confusion matrix with k= 3 :\n",
      " [[21  7]\n",
      " [ 6 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.78      0.76        27\n",
      "         Yes       0.88      0.87      0.88        53\n",
      "\n",
      "    accuracy                           0.84        80\n",
      "   macro avg       0.82      0.82      0.82        80\n",
      "weighted avg       0.84      0.84      0.84        80\n",
      "\n",
      "KNN confusion matrix with k= 4 :\n",
      " [[23 11]\n",
      " [ 4 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.68      0.85      0.75        27\n",
      "         Yes       0.91      0.79      0.85        53\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.79      0.82      0.80        80\n",
      "weighted avg       0.83      0.81      0.82        80\n",
      "\n",
      "KNN confusion matrix with k= 5 :\n",
      " [[16  8]\n",
      " [11 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.67      0.59      0.63        27\n",
      "         Yes       0.80      0.85      0.83        53\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.74      0.72      0.73        80\n",
      "weighted avg       0.76      0.76      0.76        80\n",
      "\n",
      "KNN confusion matrix with k= 6 :\n",
      " [[20  9]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.69      0.74      0.71        27\n",
      "         Yes       0.86      0.83      0.85        53\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.78      0.79      0.78        80\n",
      "weighted avg       0.80      0.80      0.80        80\n",
      "\n",
      "KNN confusion matrix with k= 7 :\n",
      " [[17  7]\n",
      " [10 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.71      0.63      0.67        27\n",
      "         Yes       0.82      0.87      0.84        53\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.76      0.75      0.76        80\n",
      "weighted avg       0.78      0.79      0.78        80\n",
      "\n",
      "KNN confusion matrix with k= 8 :\n",
      " [[19 11]\n",
      " [ 8 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.63      0.70      0.67        27\n",
      "         Yes       0.84      0.79      0.82        53\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.74      0.75      0.74        80\n",
      "weighted avg       0.77      0.76      0.77        80\n",
      "\n",
      "KNN confusion matrix with k= 9 :\n",
      " [[11  4]\n",
      " [16 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.73      0.41      0.52        27\n",
      "         Yes       0.75      0.92      0.83        53\n",
      "\n",
      "    accuracy                           0.75        80\n",
      "   macro avg       0.74      0.67      0.68        80\n",
      "weighted avg       0.75      0.75      0.73        80\n",
      "\n",
      "KNN confusion matrix with k= 10 :\n",
      " [[12  8]\n",
      " [15 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.60      0.44      0.51        27\n",
      "         Yes       0.75      0.85      0.80        53\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.68      0.65      0.65        80\n",
      "weighted avg       0.70      0.71      0.70        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I also tested knn to double check that I had the best model\n",
    "\n",
    "for k in range(10):\n",
    "    # Your code here (and delete the 'pass' line)\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k+1)\n",
    "    pred = knn.fit(x_train[['Advertising', 'Population']], y_train).predict(x_test[['Advertising', 'Population']])\n",
    "    print('KNN confusion matrix with k=', (k+1), ':\\n', confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions 6-9\n",
    "\n",
    "(Each of the three questions below carries the same weight as the earlier questions.)\n",
    "\n",
    "Question 6: What was the first method you tried, and what was its best overall accuracy?\n",
    "\n",
    "Question 7: What was the second method you tried, and what was its best overall accuracy?\n",
    "\n",
    "Question 8: What was the third method you tried, and what was its best overall accuracy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) The first method I tried was logistic regression. The overall accuracy with all of the variables was 0.91. When I narrowed down the number of variables to 4 and 2, the overall accuracy was 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) The second method I tried was Least Discriminant Analysis (LDA). The overall accuracy was 0.91, so it was a good model but not as good as the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) The third method I tried was Quadratic Discriminant Analysis (QDA). The overall accuracy was the same as LR, 0.93. So, LR and QDA were the best models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note) I also tried kNN for K=1-10, and got the best overall accuracy to be 0.85 at K=1. This was still lower than any of the other methods I tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
